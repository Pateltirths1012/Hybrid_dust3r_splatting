{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import numpy as np\n",
    "import pycolmap\n",
    "import cv2\n",
    "import trimesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scene.colmap_loader import rotmat2qvec\n",
    "from dust3r.cloud_opt import global_aligner, GlobalAlignerMode\n",
    "from dust3r.image_pairs import make_pairs\n",
    "from dust3r.utils.device import to_numpy\n",
    "from dust3r.utils.image import load_images\n",
    "from dust3r.inference import inference as run_depth_inference, load_model\n",
    "sys.path.append('dust3r')\n",
    "sys.path.append('gaussian-splatting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invert_4x4(matrix):\n",
    "    return torch.inverse(matrix) if isinstance(matrix, torch.Tensor) else np.linalg.inv(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_to_numpy(tensor: torch.Tensor):\n",
    "    return tensor.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def locate_image_files(directory: Path):\n",
    "    imgs = sorted([f for f in directory.iterdir() if f.suffix.lower() in ['.png', '.jpg']],\n",
    "                  key=lambda x: int(x.stem))\n",
    "    if not imgs:\n",
    "        raise FileNotFoundError(\"No image files found in the given directory.\")\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference_on_depth(img_files, model_ckpt, dev, img_resolution, pair_strateg, batch_sz):\n",
    "    mdl = load_model(model_ckpt, dev)\n",
    "    imgs_tensor = load_images([str(f) for f in img_files], size=img_resolution)\n",
    "    pair_config = make_pairs(\n",
    "        imgs_tensor, scene_graph=pair_strateg, prefilter=None, symmetrize=True)\n",
    "    depth_res = run_depth_inference(pair_config, mdl, dev, batch_size=batch_sz)\n",
    "    return imgs_tensor, depth_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_global_alignment(inferred_data, dev, iterations, sched, lr_val, conf_threshold):\n",
    "    align_handle = global_aligner(\n",
    "        inferred_data, device=dev, mode=GlobalAlignerMode.PointCloudOptimizer)\n",
    "    align_handle.min_conf_thr = float(\n",
    "        align_handle.conf_trf(torch.tensor(conf_threshold)))\n",
    "    align_handle.compute_global_alignment(\n",
    "        init=\"mst\", niter=iterations, schedule=sched, lr=lr_val)\n",
    "    return align_handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_scene_info(align_obj):\n",
    "    intrinsic_params = tensor_to_numpy(align_obj.get_intrinsics())\n",
    "    cam2world_mats = tensor_to_numpy(align_obj.get_im_poses())\n",
    "    world2cam_mats = invert_4x4(cam2world_mats)\n",
    "    principal_pts = tensor_to_numpy(align_obj.get_principal_points())\n",
    "    focal_lengths = tensor_to_numpy(align_obj.get_focals())\n",
    "    raw_imgs = np.array(align_obj.imgs)\n",
    "    pts3d_data = [p.detach() for p in align_obj.get_pts3d()]\n",
    "    bin_masks = to_numpy(align_obj.get_masks())\n",
    "    return intrinsic_params, cam2world_mats, world2cam_mats, principal_pts, focal_lengths, raw_imgs, pts3d_data, bin_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_geometry(pts3d_arrays, masks_arrays, c2w_matrices):\n",
    "    all_valid_pts = []\n",
    "    for pts, msk in zip(pts3d_arrays, masks_arrays):\n",
    "        chosen = pts[torch.from_numpy(msk).bool()].view(-1, 3)\n",
    "        all_valid_pts.append(chosen)\n",
    "\n",
    "    combined_pts = torch.cat(all_valid_pts, dim=0)\n",
    "    midpoint = combined_pts.mean(dim=0)\n",
    "    scale_factor = torch.norm(combined_pts - midpoint, dim=1).max()\n",
    "\n",
    "    normalized_pts3d = []\n",
    "    mod_c2w = []\n",
    "    midpoint_np = midpoint.numpy()\n",
    "    scale_np = scale_factor.item()\n",
    "\n",
    "    for pts, mat in zip(pts3d_arrays, c2w_matrices):\n",
    "        adjusted_pts = (pts - midpoint) / scale_factor\n",
    "        normalized_pts3d.append(adjusted_pts)\n",
    "        mat_copy = mat.copy()\n",
    "        mat_copy[:3, 3] = (mat_copy[:3, 3] - midpoint_np) / scale_np\n",
    "        mod_c2w.append(mat_copy)\n",
    "\n",
    "    return normalized_pts3d, mod_c2w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_scene_output_environment(dest_dir: Path):\n",
    "    if not dest_dir.exists():\n",
    "        dest_dir.mkdir(parents=True, exist_ok=True)\n",
    "    out_img_dir = dest_dir / 'images'\n",
    "    recon_dir = dest_dir / 'sparse' / '0'\n",
    "    out_img_dir.mkdir(parents=True, exist_ok=True)\n",
    "    recon_dir.mkdir(parents=True, exist_ok=True)\n",
    "    return out_img_dir, recon_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_image_data(scene_imgs, img_dir):\n",
    "    for i, img_arr in enumerate(scene_imgs):\n",
    "        img_save_path = img_dir / f\"{i}.png\"\n",
    "        img_8bit = (img_arr * 255).astype(np.uint8)\n",
    "        final_img = cv2.cvtColor(img_8bit, cv2.COLOR_BGR2RGB)\n",
    "        cv2.imwrite(str(img_save_path), final_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pointcloud(scene_imgs, pts3d_arr, masks_arr):\n",
    "    img_np = to_numpy(scene_imgs)\n",
    "    pts_np = [to_numpy(p) for p in pts3d_arr]\n",
    "    msk_np = to_numpy(masks_arr)\n",
    "\n",
    "    combined_xyz = np.concatenate([p[m].reshape(-1, 3)\n",
    "                                  for p, m in zip(pts_np, msk_np)])\n",
    "    combined_rgb = np.concatenate(\n",
    "        [im[m].reshape(-1, 3) for im, m in zip(img_np, msk_np)])\n",
    "    xyz_sub = combined_xyz[::3]\n",
    "    rgb_sub = combined_rgb[::3]\n",
    "\n",
    "    normals_arr = np.tile([1, 0, 0], (xyz_sub.shape[0], 1))\n",
    "    pc_obj = trimesh.PointCloud(xyz_sub, colors=(rgb_sub*255).astype(np.uint8))\n",
    "    pc_obj.vertices_normal = normals_arr\n",
    "    return pc_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_initial_view(xyz_coords, focal_list, princ_points, w2c_mats, imgs_arr):\n",
    "    height, width = imgs_arr.shape[1], imgs_arr.shape[2]\n",
    "    fx = focal_list[0][0]\n",
    "    fy = fx\n",
    "    cx, cy = princ_points[0]\n",
    "    rot_mat = w2c_mats[0, :3, :3]\n",
    "    qw, qx, qy, qz = rotmat2qvec(rot_mat)\n",
    "    tx, ty, tz = w2c_mats[0, :3, 3]\n",
    "    R_mat = pycolmap.Rotation3d(np.array([qx, qy, qz, qw])).matrix()\n",
    "    t_vec = np.array([tx, ty, tz]).reshape(3, 1)\n",
    "\n",
    "    cam_space = (R_mat @ xyz_coords.T + t_vec).T\n",
    "    x_proj = (cam_space[:, 0]*fx / cam_space[:, 2]) + cx\n",
    "    y_proj = (cam_space[:, 1]*fy / cam_space[:, 2]) + cy\n",
    "\n",
    "    forward = cam_space[:, 2] > 0\n",
    "    in_frame = (x_proj >= 0) & (x_proj < width) & (\n",
    "        y_proj >= 0) & (y_proj < height)\n",
    "    valid_pts = forward & in_frame\n",
    "\n",
    "    return xyz_coords[valid_pts], np.stack([x_proj[valid_pts], y_proj[valid_pts]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_reconstruction(w2c_mats, focal_vals, ppoints, imgs_arr, valid_xyz, init_keypoints, clr_data, recon_dir):\n",
    "    reconstruction = pycolmap.Reconstruction()\n",
    "    h, w = imgs_arr.shape[1], imgs_arr.shape[2]\n",
    "\n",
    "    for i, (focal, pp) in enumerate(zip(focal_vals, ppoints), start=1):\n",
    "        fx = fy = focal[0]\n",
    "        cx, cy = pp\n",
    "        cam = pycolmap.Camera(\n",
    "            model='PINHOLE',\n",
    "            width=w,\n",
    "            height=h,\n",
    "            params=[fx, fy, cx, cy]\n",
    "        )\n",
    "        cam.camera_id = i\n",
    "        reconstruction.add_camera(cam)\n",
    "\n",
    "    first_rot = w2c_mats[0, :3, :3]\n",
    "    qw, qx, qy, qz = rotmat2qvec(first_rot)\n",
    "    r_1 = pycolmap.Rotation3d(np.array([qx, qy, qz, qw]))\n",
    "    t_1 = w2c_mats[0, :3, 3]\n",
    "    first_tf = pycolmap.Rigid3d(r_1, t_1)\n",
    "    first_img = pycolmap.Image(\n",
    "        name=\"0.png\",\n",
    "        cam_from_world=first_tf,\n",
    "        camera_id=1,\n",
    "        keypoints=init_keypoints\n",
    "    )\n",
    "    first_img.image_id = 1\n",
    "    reconstruction.add_image(first_img)\n",
    "\n",
    "    for i in range(1, w2c_mats.shape[0]):\n",
    "        img_id = i + 1\n",
    "        rot_next = w2c_mats[i, :3, :3]\n",
    "        qw, qx, qy, qz = rotmat2qvec(rot_next)\n",
    "        r_next = pycolmap.Rotation3d(np.array([qx, qy, qz, qw]))\n",
    "        t_next = w2c_mats[i, :3, 3]\n",
    "        next_tf = pycolmap.Rigid3d(r_next, t_next)\n",
    "        next_img = pycolmap.Image(\n",
    "            name=f\"{i}.png\",\n",
    "            cam_from_world=next_tf,\n",
    "            camera_id=img_id\n",
    "        )\n",
    "        next_img.image_id = img_id\n",
    "        reconstruction.add_image(next_img)\n",
    "\n",
    "    for idx, (pt_3d, col_v) in enumerate(zip(valid_xyz, clr_data)):\n",
    "        xyz_col = pt_3d.astype(np.float64).reshape((3, 1))\n",
    "        rgb_val = col_v[:3].astype(np.uint8).reshape((3, 1))\n",
    "        track_el = pycolmap.Track(\n",
    "            elements=[pycolmap.TrackElement(image_id=1, point2D_idx=idx)])\n",
    "        p3D_id = reconstruction.add_point3D(\n",
    "            xyz=xyz_col, track=track_el, color=rgb_val)\n",
    "        reconstruction.images[1].set_point3D_for_point2D(idx, p3D_id)\n",
    "\n",
    "    reconstruction.write(recon_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "program_params = {\n",
    "    \"target_object\": \"husky\",\n",
    "    \"base_image_dir\": Path('images'),\n",
    "    \"model_checkpoint\": \"dust3r/checkpoints/DUSt3R_ViTLarge_BaseDecoder_512_dpt.pth\",\n",
    "    \"inference_device\": \"cuda:0\",\n",
    "    \"input_resolution\": 512,\n",
    "    \"pair_strat\": \"complete\",\n",
    "    \"inference_batch\": 32,\n",
    "    \"global_alignment_iters\": 250,\n",
    "    \"init_learning_rate\": 0.01,\n",
    "    \"min_confidence_thres\": 25,\n",
    "    \"do_normalization\": False,\n",
    "    \"learning_rate_policy\": \"cosine\",\n",
    "    \"scene_output_dir\": Path('results-dust3r')\n",
    "}\n",
    "\n",
    "input_directory = Path.joinpath(\n",
    "    program_params['base_image_dir'], program_params['target_object'])\n",
    "image_files = locate_image_files(input_directory)\n",
    "\n",
    "scene_images, depth_inference = run_inference_on_depth(\n",
    "    image_files,\n",
    "    program_params[\"model_checkpoint\"],\n",
    "    program_params[\"inference_device\"],\n",
    "    program_params[\"input_resolution\"],\n",
    "    program_params[\"pair_strat\"],\n",
    "    program_params[\"inference_batch\"]\n",
    ")\n",
    "\n",
    "alignment_op = execute_global_alignment(\n",
    "    depth_inference,\n",
    "    program_params[\"inference_device\"],\n",
    "    program_params[\"global_alignment_iters\"],\n",
    "    program_params[\"learning_rate_policy\"],\n",
    "    program_params[\"init_learning_rate\"],\n",
    "    program_params[\"min_confidence_thres\"]\n",
    ")\n",
    "\n",
    "intrinsics, cam2world, world2cam, p_pts, focs, scene_images, scene_pts3d, scene_msks = extract_scene_info(\n",
    "    alignment_op)\n",
    "\n",
    "if program_params[\"do_normalization\"]:\n",
    "    scene_pts3d, cam2world = normalize_geometry(\n",
    "        scene_pts3d, scene_msks, cam2world)\n",
    "    world2cam = np.linalg.inv(cam2world)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = Path.joinpath(\n",
    "    program_params['scene_output_dir'], program_params['target_object'])\n",
    "images_dir, reconstruction_dir = build_scene_output_environment(out_dir)\n",
    "export_image_data(scene_images, images_dir)\n",
    "\n",
    "pc_obj = create_pointcloud(scene_images, scene_pts3d, scene_msks)\n",
    "xyz_points = pc_obj.vertices\n",
    "col_points = pc_obj.colors\n",
    "\n",
    "valid_xyzs, kpts_first = project_initial_view(\n",
    "    xyz_points, focs, p_pts, world2cam, scene_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "construct_reconstruction(world2cam, focs, p_pts, scene_images,\n",
    "                         valid_xyzs, kpts_first, col_points, reconstruction_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_path = \"gaussian-splatting\"\n",
    "obj_nm = program_params['target_object']\n",
    "d3r_output_dir = str(out_dir\n",
    "gs_output_dir = str(Path.joinpath(Path(\"results-gaussian-splatting\"), obj_nm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train gaussian splatting on dust3r results\n",
    "!python \"{gs_path}/train.py\" -s \"{d3r_output_dir}\" -m \"{gs_output_dir}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# render model\n",
    "!python \"{gs_path}/render.py\" -m \"{gs_output_dir}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interactive viewer\n",
    "!\"./{gs_path}/SIBR_viewers/install/bin/SIBR_gaussianViewer_app\" -m \"{gs_output_dir}\" "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
